# jemdoc: menu{MENU}{hao.html}
= Project -- Simulating Pick and Place Operation Using AR Markers

== 1. Introduction

In this project, we simulate robot's pick and place in [http://gazebosim.org/ gzaebo]. In the simulated enviorment we place a pr2 robot with kinect sensor, a table with a object on it. Our goal is to let pr2 complete pick and place operation as following. Firstly it moves to table and stops at an appropriate point. Then it can recognize the  object using kinect, synthenize a motion plan to pick this object by gripper and place it on a pointed position of table. Here, we use AR markers to mark the appropriate position in front of table, the object's position and the position where we want to place object. 

(To be continued...)  

== 2. Hardware and Software Requirements

~~~
{hardware required}

~~~

~~~
{software required}
- ROS Indigo
- Gazebo
- [http://moveit.ros.org/ MoveIt!]
- API
    -- [http://wiki.ros.org/amcl amcl]
    -- [http://wiki.ros.org/ar_track_alvar ar_track_alvar]
~~~


== 3. Code

~~~
you can find the code of this project [https://github.com/CRSLabASU/CRSLabASU.github.io here]
~~~
(To be continued...)

== 4. Intructions

The steps of project is as following:

1. launch a new environment in gazebo with a pr2 robot, a table and a object on table. you can use this command to launch: 
~~~
	*roslaunch pr2_gazebo pr2_our_world.launch*
~~~  

2. Add three AR markers to label the position where robot stops in front of table, the position of object and the position where to place object. We have done this step in previous launch file, or you can write your own launch file.

3. AR tags can be captured by kinect sensor on pr2. In order to identify and track the pose of individual AR tags, we can use ROS package ar_track_alvar which can integrate kinect depth data for better pose estimates. You can simply type:
~~~
	*roslaunch ar_track_alvar pr2_indiv.launch*
~~~

4. You are almost ready to move the robot to the position of Ar marker which locates in front of table. We need a localization system for a robot moving, thus we can get the current pose of robot and determine whether robot reaches the objective position. Here we use ROS API amcl:
~~~
	*rosrun amcl amcl scan:=base_scan*
~~~

5. We also need to write a node to subscibe the topics which publish the pose info of AR tags and robot's current pose, publish velocity message to move robot until it gets to objective position. In our code, this node is moving_to_table, you can run it by typing:
~~~
	*rosrun my_robot_manipulation moving_to_table*
~~~

6. Finally, perfom pick and place operation. Here we use tool MoveIt! for motion planning. Use the launch file that you created in configuring Moveit!:
~~~
	*roslaunch your_pr2_moveit_generated moveit_planning_execution.launch*
~~~ 
Then running node pick_place to execute actions in gazebo

(To be continued...)

== 5. Notes

(To be continued...)
